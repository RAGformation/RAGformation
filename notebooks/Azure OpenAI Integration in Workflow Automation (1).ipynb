{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff807202-bd7b-4261-a2cc-b13b0e829762",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (1.0.1)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: llama-index in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (0.11.17)\nRequirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.4.0)\nRequirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.10 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.13)\nRequirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.0)\nRequirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.3.0)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.11.17)\nRequirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.3.1)\nRequirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.5)\nRequirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.0)\nRequirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.2)\nRequirement already satisfied: nltk>3.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (3.9.1)\nRequirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.2.2)\nRequirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.9.48.post3)\nRequirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index) (0.3.4)\nRequirement already satisfied: openai>=1.14.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.51.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2024.9.0)\nRequirement already satisfied: requests>=2.31.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2.32.3)\nRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2.0.35)\nRequirement already satisfied: PyYAML>=6.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (6.0.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (4.66.5)\nRequirement already satisfied: wrapt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.16.0)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.0.8)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.6.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (4.12.2)\nRequirement already satisfied: httpx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.27.2)\nRequirement already satisfied: tiktoken>=0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.8.0)\nRequirement already satisfied: deprecated>=1.2.9.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.2.14)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (9.4.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2.9.2)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.23.5)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (8.5.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.9.0)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.6.7)\nRequirement already satisfied: networkx>=3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (3.4.1)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (3.10.10)\nRequirement already satisfied: llama-cloud>=0.0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.1.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.5.3)\nRequirement already satisfied: pypdf<5.0.0,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.3.1)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\nRequirement already satisfied: striprtf<0.0.27,>=0.0.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\nRequirement already satisfied: llama-parse>=0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.7)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (22.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (2.4.3)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.15.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (6.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (4.0.3)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.3.2.post1)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.5.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (2022.12.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.2.0)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.0.6)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.4)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.14.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (1.7.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.4->llama-index) (0.6.1)\nRequirement already satisfied: pydantic-core==2.23.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.7.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.4.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.22.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2022.7)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.17->llama-index) (23.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.2.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: llama-index-utils-workflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (0.2.1)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-utils-workflow) (0.11.17)\nRequirement already satisfied: pyvis<0.4.0,>=0.3.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-utils-workflow) (0.3.2)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (9.4.0)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (8.5.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.6.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (2.9.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (3.10.10)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (0.9.0)\nRequirement already satisfied: typing-extensions>=4.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (4.12.2)\nRequirement already satisfied: httpx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (0.27.2)\nRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (2.0.35)\nRequirement already satisfied: PyYAML>=6.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (6.0.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (2024.9.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (0.8.0)\nRequirement already satisfied: deprecated>=1.2.9.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.2.14)\nRequirement already satisfied: requests>=2.31.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (2.32.3)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (4.66.5)\nRequirement already satisfied: wrapt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.16.0)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.0.8)\nRequirement already satisfied: nltk>3.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.23.5)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (0.6.7)\nRequirement already satisfied: networkx>=3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (3.4.1)\nRequirement already satisfied: jinja2>=2.9.6 in /databricks/python3/lib/python3.10/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.1.2)\nRequirement already satisfied: ipython>=5.3.0 in /databricks/python3/lib/python3.10/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (8.14.0)\nRequirement already satisfied: jsonpickle>=1.4.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (3.3.0)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.15.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (6.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (2.4.3)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (22.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-utils-workflow) (4.0.3)\nRequirement already satisfied: pexpect>4.3 in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (4.8.0)\nRequirement already satisfied: pygments>=2.4.0 in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (2.11.2)\nRequirement already satisfied: stack-data in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.0)\nRequirement already satisfied: decorator in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.1.1)\nRequirement already satisfied: traitlets>=5 in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (5.7.1)\nRequirement already satisfied: pickleshare in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.7.5)\nRequirement already satisfied: jedi>=0.16 in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.18.1)\nRequirement already satisfied: matplotlib-inline in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.1.6)\nRequirement already satisfied: backcall in /databricks/python3/lib/python3.10/site-packages (from ipython>=5.3.0->pyvis<0.4.0,>=0.3.2->llama-index-utils-workflow) (0.2.0)\n\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n.5)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from openai) (4.12.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /databricks/python3/lib/python3.10/site-packages (from openai) (3.5.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from openai) (0.27.2)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2022.12.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: requests>=2.31.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2.32.3)\nRequirement already satisfied: PyYAML>=6.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (8.5.0)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (9.4.0)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.0.8)\nRequirement already satisfied: deprecated>=1.2.9.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.2.14)\nRequirement already satisfied: tiktoken>=0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.8.0)\nRequirement already satisfied: wrapt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.16.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.6.0)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (1.23.5)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (3.10.10)\nRequirement already satisfied: networkx>=3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (3.4.1)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.9.0)\nRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2.0.35)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (0.6.7)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.17->llama-index) (2024.9.0)\nRequirement already satisfied: llama-cloud>=0.0.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index) (0.1.2)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.10/site-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.5.3)\nRequirement already satisfied: pypdf<5.0.0,>=4.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.3.1)\nRequirement already satisfied: striprtf<0.0.27,>=0.0.26 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (0.0.26)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (4.12.3)\nRequirement already satisfied: llama-parse>=0.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index) (0.5.7)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (2024.9.11)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (2.4.3)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.15.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (4.0.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (22.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (6.1.0)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (1.26.14)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.4.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.17->llama-index) (3.22.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.10/site-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (2022.7)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.17->llama-index) (23.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index) (1.16.0)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.17->llama-index) (0.2.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: llama-index-llms-azure-openai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (0.2.2)\nRequirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (1.19.0)\nRequirement already satisfied: llama-index-core<0.12.0,>=0.11.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.11.17)\nRequirement already satisfied: httpx in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.27.2)\nRequirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.2.13)\nRequirement already satisfied: cryptography>=2.5 in /databricks/python3/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (39.0.1)\nRequirement already satisfied: typing-extensions>=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (4.12.2)\nRequirement already satisfied: msal-extensions>=1.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.2.0)\nRequirement already satisfied: azure-core>=1.31.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.31.0)\nRequirement already satisfied: msal>=1.30.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.31.0)\nRequirement already satisfied: nltk>3.8.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.9.1)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.0.8)\nRequirement already satisfied: requests>=2.31.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.32.3)\nRequirement already satisfied: pillow>=9.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (9.4.0)\nRequirement already satisfied: PyYAML>=6.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (6.0.2)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (8.5.0)\nRequirement already satisfied: numpy<2.0.0 in /databricks/python3/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.23.5)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.10.10)\nRequirement already satisfied: dataclasses-json in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.6.7)\nRequirement already satisfied: typing-inspect>=0.8.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.9.0)\nRequirement already satisfied: networkx>=3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.4.1)\nRequirement already satisfied: deprecated>=1.2.9.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.2.14)\nRequirement already satisfied: fsspec>=2023.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2024.9.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (4.66.5)\nRequirement already satisfied: tiktoken>=0.3.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.8.0)\nRequirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.0.35)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.6.0)\nRequirement already satisfied: wrapt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.16.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.9.2)\nRequirement already satisfied: openai<2.0.0,>=1.40.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai) (1.51.2)\nRequirement already satisfied: anyio in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (3.5.0)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (2022.12.7)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (1.0.6)\nRequirement already satisfied: idna in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (3.4)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (1.2.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai) (0.14.0)\nRequirement already satisfied: yarl<2.0,>=1.12.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.15.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (6.1.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.4.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.4.1)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (22.1.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (4.0.3)\nRequirement already satisfied: six>=1.11.0 in /usr/lib/python3/dist-packages (from azure-core>=1.31.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.16.0)\nRequirement already satisfied: cffi>=1.12 in /databricks/python3/lib/python3.10/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.15.1)\nRequirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal>=1.30.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.3.0)\nRequirement already satisfied: portalocker<3,>=1.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from msal-extensions>=1.2.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.10.1)\nRequirement already satisfied: regex>=2021.8.3 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2024.9.11)\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (8.0.4)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai) (1.7.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from openai<2.0.0,>=1.40.0->llama-index-llms-openai<0.3.0,>=0.2.1->llama-index-llms-azure-openai) (0.6.1)\nRequirement already satisfied: pydantic-core==2.23.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.23.4)\nRequirement already satisfied: annotated-types>=0.6.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.7.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (1.26.14)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (2.0.4)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.4.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (3.22.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (2.21)\nRequirement already satisfied: packaging>=17.0 in /databricks/python3/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (23.2)\nRequirement already satisfied: propcache>=0.2.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-llms-azure-openai) (0.2.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install --upgrade llama-index\n",
    "%pip install llama-index-utils-workflow\n",
    "%pip install colorama\n",
    "%pip install llama-index openai\n",
    "%pip install llama-index-llms-azure-openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf7faa8-65bb-4924-a124-5d90276c419c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0b9723d-e6f6-4407-bb8f-7361c01ea332",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concierge_flows.html\nRunning step concierge\nStep concierge produced event InitializeEvent\nRunning step initialize\nStep initialize produced event ConciergeEvent\nRunning step concierge\n\u001B[35mHello! How can I assist you today? Here are some things I can help you with:\n\n- Requirement gathering\n- Flow confirmation\n- Flow enhancement\n- Price lookup\n- Final report of selected flow\n\nPlease let me know what you need help with, and we'll get started!\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       ">  Price lookup"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step concierge produced event OrchestratorEvent\nRunning step orchestrator\nOrchestrator received request: Price lookup\n__emitted: price lookup\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py:316: UserWarning: Use a Context instance to send events from a step. Make sure your step method or function takes a parameter of type Context like `ctx: Context` and replace `self.send_event(...)` with `ctx.send_event(...)` in your code.\n  warnings.warn(msg)\nException in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-5b3324c2c444', bound_args=<BoundArguments ()>, instance=<__main__.Con...x7fc39488b0d0>, context=<_contextvars...x7fc39510fb40>)(<WorkflowHand...rice_lookup')>) at /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:273\nhandle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-5b3324c2c444', bound_args=<BoundArguments ()>, instance=<__main__.Con...x7fc39488b0d0>, context=<_contextvars...x7fc39510fb40>)(<WorkflowHand...rice_lookup')>) at /local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py:273>\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 281, in handle_future_result\n    result = future.result()\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py\", line 376, in _run_workflow\n    raise exception_raised\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py\", line 233, in _task\n    raise e from None\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/workflow/workflow.py\", line 229, in _task\n    new_ev = await instrumented_step(**kwargs)\n  File \"/local_disk0/.ephemeral_nfs/envs/pythonEnv-f1b892fb-9e08-47a2-8196-2d3bb4a877d9/lib/python3.10/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 353, in async_wrapper\n    result = await func(*args, **kwargs)\n  File \"/home/spark-f1b892fb-9e08-47a2-8196-2d/.ipykernel/66054/command-4366692243010018-3569536273\", line 373, in price_lookup\n    self.log_history(ctx, \"price_lookup\", \"user\", ev.request)\n  File \"/home/spark-f1b892fb-9e08-47a2-8196-2d/.ipykernel/66054/command-4366692243010018-3569536273\", line 73, in log_history\n    ctx.data[agent].append({\nKeyError: 'price_lookup'\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step orchestrator produced no event\nRunning step price_lookup\nPrice Lookup received request: Price lookup\n'price_lookup'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    step,\n",
    "    Context,\n",
    "    Workflow,\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent\n",
    ")\n",
    "\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "LLM = \"AzureOpenAI\"\n",
    "# except ImportError as e:\n",
    "#     AzureOpenAI = None\n",
    "#     print(e)\n",
    "# try:\n",
    "#     from llama_index.llms.ollama import Ollama\n",
    "#     LLM = \"Ollama\"\n",
    "# except ImportError as e:\n",
    "#     Ollama = None\n",
    "#     print(e)\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from typing import Optional, List, Callable\n",
    "from colorama import Fore, Style\n",
    "\n",
    "class InitializeEvent(Event):\n",
    "    pass\n",
    "\n",
    "class ConciergeEvent(Event):\n",
    "    request: Optional[str] = None\n",
    "    just_completed: Optional[str] = None\n",
    "    need_help: Optional[bool] = False\n",
    "\n",
    "class OrchestratorEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class AuthenticateEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class PriceLookupEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class ImageToTextEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class TextToDiagramEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class TextToRAGEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class ReporterEvent(Event):\n",
    "    request: str\n",
    "\n",
    "class Message:\n",
    "    role: str = None\n",
    "    content: Optional[str] = None\n",
    "\n",
    "class ConciergeWorkflow(Workflow):\n",
    "\n",
    "    @staticmethod\n",
    "    def log_history(ctx: Context, agent, role, content):\n",
    "        # TODO: log system prompts (on first call)\n",
    "        # TODO: log assistant responses\n",
    "        ctx.data[agent].append({\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "        })\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def initialize(self, ctx: Context, ev: InitializeEvent) -> ConciergeEvent:\n",
    "        ctx.data[\"user\"] = {\n",
    "            \"username\": None,\n",
    "            \"session_token\": None,\n",
    "            \"account_id\": None,\n",
    "        }\n",
    "        ctx.data[\"success\"] = None\n",
    "        ctx.data[\"redirecting\"] = None\n",
    "        ctx.data[\"overall_request\"] = None\n",
    "        ctx.data[\"location\"] = None\n",
    "\n",
    "        ctx.data[\"history\"]: dict[str, List[Message]] = {\n",
    "            \"authenticate\": [],\n",
    "            \"price_lookup\": [],\n",
    "            \"image_to_text\": [],\n",
    "            \"text_to_diagram\": [],\n",
    "            \"text_to_rag\": [],\n",
    "            \"report\": [],\n",
    "        }\n",
    "        ctx.data[\"requirements\"] = None\n",
    "        ctx.data[\"flow_confirmed\"] = False\n",
    "\n",
    "        if LLM == \"AzureOpenAI\" and callable(AzureOpenAI):\n",
    "            ctx.data[\"llm\"] = AzureOpenAI(\n",
    "                engine=\"testing-first-gbu-doc\", model=\"gpt-4o\", temperature=0.4\n",
    "            )\n",
    "        elif LLM == \"Ollama\" and callable(Ollama):\n",
    "            ctx.data[\"llm\"] = Ollama(model=\"llama3.1:8b\", request_timeout=120.0)\n",
    "\n",
    "        return ConciergeEvent()\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def concierge(self, ctx: Context, ev: ConciergeEvent | StartEvent) -> InitializeEvent | StopEvent | OrchestratorEvent:\n",
    "        # initialize user if not already done\n",
    "        if \"user\" not in ctx.data:\n",
    "            return InitializeEvent()\n",
    "\n",
    "        # initialize concierge if not already done\n",
    "        if \"concierge\" not in ctx.data:\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that is helping a user navigate an automatic system AWS diagram generator, reporter and pricing.\n",
    "\n",
    "                Behavioral Guidelines:\n",
    "                - Be proactive: Suggest actions or steps that can improve efficiency or correctness.\n",
    "                - Be transparent: Clearly explain each decision and the results of executed actions. If an action fails, explain why and attempt a fallback solution.\n",
    "                - Be adaptive: Modify your behavior based on feedback from the environment or user instructions.\n",
    "                - Be polite and helpful: Always maintain a helpful tone and seek the best possible outcomes for the user.\n",
    "                - Be concise and clear: Use simple and concise language to avoid unnecessary details and confusion.\n",
    "                Tools at Your Disposal:\n",
    "                - price lookup\n",
    "                - image to text\n",
    "                - text to diagram\n",
    "                - text to rag\n",
    "                - reporter\n",
    "                Your job is to ask the user questions to figure out what they want to do, and start by listing the things you can help them do:\n",
    "                - Requirement gathering\n",
    "                - Flow confirmation\n",
    "                - Flow enhancement\n",
    "                - Price lookup\n",
    "                - Final report of selected flow \n",
    "\n",
    "                Then use the respective tool to fulfill the user's request.            \n",
    "            \"\"\")\n",
    "\n",
    "            agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "                tools=[],\n",
    "                llm=ctx.data[\"llm\"],\n",
    "                allow_parallel_tool_calls=False,\n",
    "                system_prompt=system_prompt\n",
    "            )\n",
    "            ctx.data[\"concierge\"] = agent_worker.as_agent()\n",
    "\n",
    "        concierge = ctx.data[\"concierge\"]\n",
    "        if ctx.data[\"overall_request\"] is not None:\n",
    "            print(\"There's an overall request in progress, it's \", ctx.data[\"overall_request\"])\n",
    "            last_request = ctx.data[\"overall_request\"]\n",
    "            ctx.data[\"overall_request\"] = None\n",
    "            return OrchestratorEvent(request=last_request)\n",
    "        elif ev.just_completed is not None:\n",
    "            response = concierge.chat(f\"FYI, the user has just completed the task: {ev.just_completed}\")\n",
    "        elif ev.need_help:\n",
    "            print(\"The previous process needs help with \", ev.request)\n",
    "            return OrchestratorEvent(request=ev.request)\n",
    "        else:\n",
    "            # first time experience\n",
    "            response = concierge.chat(\"Hello!\")\n",
    "\n",
    "        print(Fore.MAGENTA + str(response) + Style.RESET_ALL)\n",
    "        user_msg_str = input(\"> \").strip()\n",
    "        return OrchestratorEvent(request=user_msg_str)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def orchestrator(self, ctx: Context, ev: OrchestratorEvent) -> ConciergeEvent | AuthenticateEvent | PriceLookupEvent | ImageToTextEvent | TextToDiagramEvent | TextToRAGEvent | ReporterEvent | StopEvent:\n",
    "\n",
    "        print(f\"Orchestrator received request: {ev.request}\")\n",
    "\n",
    "        def emit_authenticate() -> bool:\n",
    "            \"\"\"Call this if the user wants to authenticate\"\"\"\n",
    "            print(\"__emitted: authenticate\")\n",
    "            self.send_event(AuthenticateEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_price_lookup() -> bool:\n",
    "            \"\"\"Call this if the user wants to look up the price of a service.\"\"\"\n",
    "            print(\"__emitted: price lookup\")\n",
    "            self.send_event(PriceLookupEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_image_to_text() -> bool:\n",
    "            \"\"\"\n",
    "            Call this function when the user sends an image to extract text, which is then sent to the RAG (Retrieval-Augmented Generation) tool for further processing.\n",
    "\n",
    "            This function emits an event to trigger the text extraction process from the provided image.\n",
    "\n",
    "            Args:\n",
    "                ev (Event): The event containing the image data and request details.\n",
    "\n",
    "            Returns:\n",
    "                bool: Returns True if the event is successfully emitted for text extraction, False otherwise.\n",
    "            \"\"\"\n",
    "            print(\"__emitted: image to text\")\n",
    "            self.send_event(ImageToTextEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_text_to_diagram() -> bool:\n",
    "            \"\"\" Call this function once the RAG generates a list of AWS services \n",
    "            and you want to generate a diagram from the text description using AWS.\n",
    "\n",
    "            This function triggers the generation of a diagram based on the provided \n",
    "            event (which contains the AWS service list) and sends it through \n",
    "            the necessary workflow event handler.\n",
    "\n",
    "            Args:\n",
    "                ev (Event): The event containing the request and generated AWS service list.\n",
    "\n",
    "            Returns:\n",
    "                bool: Returns True if the event is successfully sent for diagram generation.\n",
    "            \"\"\"\n",
    "            print(\"__emitted: text to diagram\")\n",
    "            self.send_event(TextToDiagramEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_text_to_rag() -> bool:\n",
    "            \"\"\"\n",
    "            Call this function when a AWS service requirement or AWS service flow enhancement request is received from the user to perform a RAG (Retrieval-Augmented Generation) search using text.\n",
    "\n",
    "            This function emits an event to trigger a RAG search based on the provided event details.\n",
    "\n",
    "            Args:\n",
    "                ev (Event): The event containing the request for RAG search.\n",
    "\n",
    "            Returns:\n",
    "                bool: Returns True if the RAG search event is successfully emitted, False otherwise.\n",
    "            \"\"\"\n",
    "            print(\"__emitted: text to rag\")\n",
    "            self.send_event(TextToRAGEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_report() -> bool:\n",
    "            \"\"\"\n",
    "            Call this function if the user wants to generate a report.\n",
    "\n",
    "            This function triggers the report generation process based on the provided event,\n",
    "            which contains the necessary details for report creation.\n",
    "\n",
    "            Args:\n",
    "                ev (Event): The event containing the request with report generation details.\n",
    "\n",
    "            Returns:\n",
    "                bool: Returns True if the report generation event is successfully emitted, False otherwise.\n",
    "            \"\"\"\n",
    "            print(\"__emitted: report\")\n",
    "            self.send_event(ReporterEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_concierge() -> bool:\n",
    "            \"\"\"Call this if the user wants to do something else or you can't figure out what they want to do.\"\"\"\n",
    "            print(\"__emitted: concierge\")\n",
    "            self.send_event(ConciergeEvent(request=ev.request))\n",
    "            return True\n",
    "\n",
    "        def emit_stop() -> bool:\n",
    "            \"\"\"Call this if the user wants to stop or exit the system.\"\"\"\n",
    "            print(\"__emitted: stop\")\n",
    "            self.send_event(StopEvent())\n",
    "            return True\n",
    "\n",
    "        tools = [\n",
    "            FunctionTool.from_defaults(fn=emit_authenticate),\n",
    "            FunctionTool.from_defaults(fn=emit_price_lookup),\n",
    "            FunctionTool.from_defaults(fn=emit_image_to_text),\n",
    "            FunctionTool.from_defaults(fn=emit_text_to_diagram),\n",
    "            FunctionTool.from_defaults(fn=emit_text_to_rag),\n",
    "            FunctionTool.from_defaults(fn=emit_report),\n",
    "            FunctionTool.from_defaults(fn=emit_concierge),\n",
    "            FunctionTool.from_defaults(fn=emit_stop)\n",
    "        ]\n",
    "\n",
    "        system_prompt = (f\"\"\"\n",
    "            You are an advanced orchestrating agent designed to manage and optimize the execution of multiple subtasks within a complex workflow for AWS diagram generator, reporter and pricing. Your primary role is to coordinate between various tools, services, and APIs to ensure tasks are completed efficiently and accurately.\n",
    "            Core responsibilities:\n",
    "            - **Task delegation**: Assign each user request to the correct agent by calling the appropriate tool.\n",
    "            - **Efficiency**: Ensure that you call only **one tool at a time**, allowing agents to handle their respective dependencies.\n",
    "            - **Precision**: Match the user’s request with the right agent without making redundant calls.\n",
    "            - **Fail-safe**: If no tools are called, return the string \"FAILED\" without quotes and nothing else. This will signal that no matching agents were found for the request.\n",
    "            - **No Dependency Resolution**: You do not need to handle or figure out dependencies between agents; each agent will manage its own dependencies and outputs.\n",
    "\n",
    "            Behavioral Guidelines:\n",
    "            - **Efficiency**: Make quick and accurate decisions about which agent to call based on the user's input. Avoid redundant calls or multiple agent invocations for a single task.\n",
    "            - **Clarity**: Provide clear responses or actions based on the user’s input.\n",
    "            - **Accuracy**: Always select the most appropriate agent based on the request. If the request is ambiguous or cannot be understood, return \"FAILED.\"\n",
    "            - **No Overlap**: Each task should be handled by exactly one agent. If the task is outside your scope or the agents available, return \"FAILED.\"\n",
    "            \n",
    "            Tools at your disposal:\n",
    "            - **Price Lookup Agent**: For checking the price of a service.\n",
    "            - **Image to Text Agent**: For extracting text from an image.\n",
    "            - **Text to Diagram Agent**: For converting text descriptions into a diagram.\n",
    "            - **Text to RAG Agent**: For performing Retrieval-Augmented Generation (RAG) searches using text.\n",
    "            - **Report Generation Agent**: For generating a report of the finalized flow.\n",
    "            - **Concierge Agent**: For handling any other requests or questions not covered by the other agents.\n",
    "                            \n",
    "            If you did not call any tools, return the string \"FAILED\" without quotes and nothing else.\n",
    "            ### Decision Process:\n",
    "            - Listen carefully to the user's request.\n",
    "            - Based on the request, call the most suitable agent from the list above.\n",
    "            - Do not attempt to resolve dependencies between agents; agents will handle their own logic.\n",
    "            - If no suitable agent can be found for the user's request, respond with \"FAILED.\"\n",
    "\n",
    "            Ensure that your decisions are efficient and accurate to maintain a smooth workflow. Your goal is to streamline task execution without unnecessary steps.\n",
    "        \"\"\")\n",
    "\n",
    "        agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "            tools=tools,\n",
    "            llm=ctx.data[\"llm\"],\n",
    "            allow_parallel_tool_calls=False,\n",
    "            system_prompt=system_prompt\n",
    "        )\n",
    "        ctx.data[\"orchestrator\"] = agent_worker.as_agent()\n",
    "\n",
    "        orchestrator = ctx.data[\"orchestrator\"]\n",
    "        response = str(orchestrator.chat(ev.request))\n",
    "\n",
    "        if response == \"FAILED\":\n",
    "            print(\"Orchestration agent failed to return a valid speaker; try again\")\n",
    "            return OrchestratorEvent(request=ev.request)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def authenticate(self, ctx: Context, ev: AuthenticateEvent) -> ConciergeEvent:\n",
    "\n",
    "        self.log_history(ctx, \"authenticate\", \"user\", ev.request)\n",
    "\n",
    "        if \"authentication_agent\" not in ctx.data:\n",
    "            def store_username(username: str) -> None:\n",
    "                \"\"\"Adds the username to the user state.\"\"\"\n",
    "                print(\"Recording username\")\n",
    "                ctx.data[\"user\"][\"username\"] = username\n",
    "\n",
    "            def login(password: str) -> None:\n",
    "                \"\"\"Given a password, logs in and stores a session token in the user state.\"\"\"\n",
    "                print(f\"Logging in {ctx.data['user']['username']}\")\n",
    "                # todo: actually check the password\n",
    "                session_token = \"output_of_login_function_goes_here\"\n",
    "                ctx.data[\"user\"][\"session_token\"] = session_token\n",
    "\n",
    "            def is_authenticated() -> bool:\n",
    "                \"\"\"Checks if the user has a session token.\"\"\"\n",
    "                print(\"Checking if authenticated\")\n",
    "                if ctx.data[\"user\"][\"session_token\"] is not None:\n",
    "                    return True\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that is authenticating a user.\n",
    "                Your task is to get a valid session token stored in the user state.\n",
    "                To do this, the user must supply you with a username and a valid password. You can ask them to supply these.\n",
    "                If the user supplies a username and password, call the tool \"login\" to log them in.\n",
    "                Once you've called the login tool successfully, call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than authenticate, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"authentication_agent\"] = ConciergeAgent(\n",
    "                name=\"Authentication Agent\",\n",
    "                parent=self,\n",
    "                tools=[store_username, login, is_authenticated],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=AuthenticateEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"authentication_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def price_lookup(self, ctx: Context, ev: PriceLookupEvent) -> ConciergeEvent:\n",
    "\n",
    "        print(f\"Price Lookup received request: {ev.request}\")\n",
    "        self.log_history(ctx, \"price_lookup\", \"user\", ev.request)\n",
    "\n",
    "        if (\"price_lookup_agent\" not in ctx.data):\n",
    "            def lookup_price(name: str) -> str:\n",
    "                \"\"\"Useful for looking the price of a service.\"\"\"\n",
    "                print(f\"Looking up price for {name} service\")\n",
    "                return f\"Service {name} currently costs $100.00\"\n",
    "\n",
    "            def search_for_service(name: str) -> str:\n",
    "                \"\"\"Useful for searching for a service from a free-form description.\"\"\"\n",
    "                print(\"Searching for item or component\")\n",
    "                return name.upper()\n",
    "\n",
    "            def has_requirements() -> bool:\n",
    "                \"\"\"Checks if the user has provided the requirements.\"\"\"\n",
    "                print(\"Price Lookup checking if user has provided the requirements\")\n",
    "                if ctx.data[\"requirements\"] is not None:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "\n",
    "            def has_confirmed_flow() -> bool:\n",
    "                \"\"\"Checks if the user has confirmed the flow.\"\"\"\n",
    "                print(\"Price Lookup checking if user confirmed the flow\")\n",
    "                return ctx.data[\"requirements\"]\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that is looking up service prices.\n",
    "                The user can only request a price lookup if they have provided requirements, which you can check with the has_requirements tool.\n",
    "                The user can only request a price lookup if they have confirmed the flow, which you can check with the flow_confirmed tool.\n",
    "                The user may not know the name of the service they're interested in,\n",
    "                so you can help them look it up by a description of what the service does or provides.\n",
    "                You can only look up names given to you by the search_for_service tool, don't make them up. Trust the output of the search_for_service tool even if it doesn't make sense to you.\n",
    "                Once you have retrieved a price, you *must* call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than look up a service price, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"price_lookup_agent\"] = ConciergeAgent(\n",
    "                name=\"Price Lookup Agent\",\n",
    "                parent=self,\n",
    "                tools=[lookup_price, search_for_service, has_requirements, has_confirmed_flow],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=PriceLookupEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"price_lookup_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def image_to_text(self, ctx: Context, ev: ImageToTextEvent) -> ConciergeEvent:\n",
    "\n",
    "        print(f\"Image to Text received request: {ev.request}\")\n",
    "        self.log_history(ctx, \"image_to_text\", \"user\", ev.request)\n",
    "\n",
    "        if (\"image_to_text_agent\" not in ctx.data):\n",
    "            def extract_text(image: str) -> str:\n",
    "                \"\"\"Useful for extracting text from an image.\"\"\"\n",
    "                print(f\"Extracting text from image {image}\")\n",
    "                return f\"Image {image} contains Lorem ipsum dolor sit amet\"\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that extracts text from an image.\n",
    "                You can only extract text from images given to you by the extract_text tool, don't make them up. Trust the output of the extract_text tool even if it doesn't make sense to you.\n",
    "                Once you have extracted the text, you *must* call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than extract text from an image, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"image_to_text_agent\"] = ConciergeAgent(\n",
    "                name=\"Image to Text Agent\",\n",
    "                parent=self,\n",
    "                tools=[extract_text],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=ImageToTextEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"image_to_text_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def text_to_diagram(self, ctx: Context, ev: TextToDiagramEvent) -> ConciergeEvent:\n",
    "\n",
    "        print(f\"Text to Diagram received request: {ev.request}\")\n",
    "        self.log_history(ctx, \"text_to_diagram\", \"user\", ev.request)\n",
    "\n",
    "        if (\"text_to_diagram_agent\" not in ctx.data):\n",
    "            def generate_diagram(text: str) -> str:\n",
    "                \"\"\"Useful for describing a diagram using text.\"\"\"\n",
    "                print(f\"Generating diagram from text {text}\")\n",
    "                return f\"{text} generated a diagram\"\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that generates a diagram from text.\n",
    "                You can only generate diagrams from text given to you by the generate_diagram tool, don't make them up. Trust the output of the generate_diagram tool even if it doesn't make sense to you.\n",
    "                Once you have generated the diagram, you *must* call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than generate a diagram, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"text_to_diagram_agent\"] = ConciergeAgent(\n",
    "                name=\"Text to Diagram Agent\",\n",
    "                parent=self,\n",
    "                tools=[generate_diagram],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=TextToDiagramEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"text_to_diagram_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def text_to_rag(self, ctx: Context, ev: TextToRAGEvent) -> ConciergeEvent:\n",
    "\n",
    "        print(f\"Text to RAG received request: {ev.request}\")\n",
    "        self.log_history(ctx, \"text_to_rag\", \"user\", ev.request)\n",
    "\n",
    "        if (\"text_to_rag_agent\" not in ctx.data):\n",
    "            def search_rag(text: str) -> str:\n",
    "                \"\"\"Useful for requesting a RAG search using text.\"\"\"\n",
    "                print(f\"Performing a search from text {text}\")\n",
    "                return f\"{text} generated results\"\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that perform RAG searches from text.\n",
    "                You can only search RAG from text given to you by the search_rag tool, don't make them up. Trust the output of the search_rag tool even if it doesn't make sense to you.\n",
    "                Once you have performed the search, you *must* call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than perform a search, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"text_to_rag_agent\"] = ConciergeAgent(\n",
    "                name=\"Text to RAG Agent\",\n",
    "                parent=self,\n",
    "                tools=[search_rag],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=TextToRAGEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"text_to_rag_agent\"].handle_event(ev)\n",
    "\n",
    "    @step(pass_context=True)\n",
    "    async def report(self, ctx: Context, ev: ReporterEvent) -> ConciergeEvent:\n",
    "\n",
    "        print(f\"Report received request: {ev.request}\")\n",
    "        self.log_history(ctx, \"report\", \"user\", ev.request)\n",
    "\n",
    "        if (\"report_agent\" not in ctx.data):\n",
    "            def report() -> str:\n",
    "                \"\"\"Useful for generating a report.\"\"\"\n",
    "                print(f\"Generating report from text\")\n",
    "                return f\"Report generated\"\n",
    "\n",
    "            system_prompt = (f\"\"\"\n",
    "                You are a helpful assistant that generates a report.\n",
    "                You can only generate a report by the report tool, don't make them up. Trust the output of the report tool even if it doesn't make sense to you.\n",
    "                Once you have performed the search, you *must* call the tool named \"done\" to signal that you are done. Do this before you respond.\n",
    "                If the user asks to do anything other than generate a search, call the tool \"need_help\" to signal some other agent should help.\n",
    "            \"\"\")\n",
    "\n",
    "            ctx.data[\"report_agent\"] = ConciergeAgent(\n",
    "                name=\"Report Agent\",\n",
    "                parent=self,\n",
    "                tools=[report],\n",
    "                context=ctx,\n",
    "                system_prompt=system_prompt,\n",
    "                trigger_event=ReporterEvent\n",
    "            )\n",
    "\n",
    "        return ctx.data[\"report_agent\"].handle_event(ev)\n",
    "\n",
    "class ConciergeAgent():\n",
    "    name: str\n",
    "    parent: Workflow\n",
    "    tools: list[FunctionTool]\n",
    "    system_prompt: str\n",
    "    context: Context\n",
    "    current_event: Event\n",
    "    trigger_event: Event\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            parent: Workflow,\n",
    "            tools: List[Callable],\n",
    "            system_prompt: str,\n",
    "            trigger_event: Event,\n",
    "            context: Context,\n",
    "            name: str,\n",
    "    ):\n",
    "        self.name = name\n",
    "        self.parent = parent\n",
    "        self.context = context\n",
    "        self.system_prompt = system_prompt\n",
    "        self.context.data[\"redirecting\"] = False\n",
    "        self.trigger_event = trigger_event\n",
    "\n",
    "        # set up the tools including the ones everybody gets\n",
    "        def done() -> None:\n",
    "            \"\"\"When you complete your task, call this tool.\"\"\"\n",
    "            print(f\"{self.name} is complete\")\n",
    "            self.context.data[\"redirecting\"] = True\n",
    "            parent.send_event(ConciergeEvent(just_completed=self.name))\n",
    "\n",
    "        def need_help() -> None:\n",
    "            \"\"\"If the user asks to do something you don't know how to do, call this.\"\"\"\n",
    "            print(f\"{self.name} needs help\")\n",
    "            self.context.data[\"redirecting\"] = True\n",
    "            parent.send_event(ConciergeEvent(request=self.current_event.request,need_help=True))\n",
    "\n",
    "        self.tools = [\n",
    "            FunctionTool.from_defaults(fn=done),\n",
    "            FunctionTool.from_defaults(fn=need_help)\n",
    "        ]\n",
    "        for t in tools:\n",
    "            self.tools.append(FunctionTool.from_defaults(fn=t))\n",
    "\n",
    "        agent_worker = FunctionCallingAgentWorker.from_tools(\n",
    "            self.tools,\n",
    "            llm=self.context.data[\"llm\"],\n",
    "            allow_parallel_tool_calls=False,\n",
    "            system_prompt=self.system_prompt\n",
    "        )\n",
    "        self.agent = agent_worker.as_agent()\n",
    "\n",
    "    def handle_event(self, ev: Event):\n",
    "        self.current_event = ev\n",
    "\n",
    "        response = str(self.agent.chat(ev.request))\n",
    "        print(Fore.MAGENTA + str(response) + Style.RESET_ALL)\n",
    "\n",
    "        # if they're sending us elsewhere we're done here\n",
    "        if self.context.data[\"redirecting\"]:\n",
    "            self.context.data[\"redirecting\"] = False\n",
    "            return None\n",
    "\n",
    "        # otherwise, get some user input and then loop\n",
    "        user_msg_str = input(\"> \").strip()\n",
    "        return self.trigger_event(request=user_msg_str)\n",
    "\n",
    "draw_all_possible_flows(ConciergeWorkflow,filename=\"concierge_flows.html\")\n",
    "\n",
    "async def main():\n",
    "    c = ConciergeWorkflow(timeout=1200, verbose=True)\n",
    "    result = await c.run()\n",
    "    print(result)\n",
    "\n",
    "# Check if an event loop is already running\n",
    "if __name__ == \"__main__\":\n",
    "    import asyncio\n",
    "    try:\n",
    "        # If there's no running event loop, use asyncio.run()\n",
    "        if not asyncio.get_event_loop().is_running():\n",
    "            asyncio.run(main())\n",
    "        else:\n",
    "            # If an event loop is running, use await\n",
    "            try:\n",
    "                await main()  # For Jupyter uncomment this\n",
    "                pass\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    except RuntimeError:\n",
    "        # For environments like Jupyter that may raise errors for nested event loops\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b507bb30-38b6-4b5b-91fc-a688f6439f5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Azure OpenAI Integration in Workflow Automation",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
