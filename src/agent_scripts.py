import requests
import os
from prompts import txt_2_diagram_prompt_template
from llama_index.llms.anthropic import Anthropic

import openai
import re


from dotenv import load_dotenv
load_dotenv()


client = openai.OpenAI(
  api_key=os.environ.get("TOGETHER_API_KEY"),
  base_url="https://api.together.xyz/v1",
)
def get_code_completion(messages, max_tokens=512, model="codellama/CodeLlama-70b-Instruct-hf"):
    chat_completion = client.chat.completions.create(
        messages=messages,
        model=model,
        max_tokens=max_tokens,
        stop=[
            "<step>"
        ],
        frequency_penalty=1,
        presence_penalty=1,
        top_p=0.7,
        n=10,
        temperature=0.7,
    )
 
    return chat_completion

def extract_code(text):
    # Pattern to match code blocks with or without language specification
    pattern = r'```(?:python)?\s*([\s\S]*?)\s*```'
    matches = re.findall(pattern, text, re.MULTILINE)
    return matches

def image_to_text(image_url: str) -> str:
    """
    Convert an image to text using an API call.
    
    Args:
        image_url (str): The URL of the image to be converted to text.
    
    Returns:
        str: The text extracted from the image.
    """
    # This is a placeholder for the actual API call
    # You would replace this with your actual API implementation
    response = requests.post(
        "https://api.example.com/image-to-text",
        json={"image_url": image_url}
    )
    return response.json()["text"]

def text_to_diagram(requirements_plan: str) -> str:
    """
    Automatically generates AWS architecture code and a corresponding visual diagram using the Diagrams Python library.
    
    Args:
        requirements_plan (str): A detailed description of the requirements for the AWS architecture.
    
    Returns:
        If the diagram generation was successful or failure
    """
    
    # llm = TogetherLLM(
    #     model="mistralai/Mixtral-8x7B-Instruct-v0.1"
    # )
    llm = Anthropic(model="claude-3-opus-20240229")
    
    prompt = txt_2_diagram_prompt_template.format(architecture_plan=requirements_plan)
    resp = str(llm.complete(prompt))
    print(resp)

    
    if resp.count("```")==2:
        resp = extract_code(resp)
    elif resp.count("```") > 0:
        resp = re.sub(r'^.*resp\s*=\s*resp\.replace\("```python",\s*"".*\n?', '', resp, flags=re.MULTILINE)
        resp = resp.replace("```", "")
        
    if isinstance(resp, list):
        if len(resp) >0:
            resp = resp[0]
    
    with open("temp_generated_code.py", "w+") as f:
        f.write(resp)

    try:
        if resp:
            exec(resp)
        else:
            diagram_image = None
            resp = None
            diagram_name = None
    except Exception as e:
        print(f"Error generating diagram: {e}")
        diagram_image = None
        return "Error generating diagram: {e}"
    
    return "Diagram generated successfully."


if __name__ == "__main__":
    user_query = """
Help me build an AWS system architecture for your machine learning Streamlit application that writes output to an S3 bucket, requires 80GB of memory, runs in Docker containers, and is expected to handle 500,000 daily users, you can follow these guidelines:\n\n1. **Compute Resources**:\n   - **Amazon ECS or EKS**: Use Amazon Elastic Container Service (ECS) or Amazon Elastic Kubernetes Service (EKS) to manage your Docker containers. Both services can scale to meet demand and can handle the orchestration of your containers.\n   - **EC2 Instances**: Choose EC2 instances with sufficient memory to support your application. For 80GB of memory, consider using memory-optimized instance types such as the R5 or R6g series. You can also use EC2 Auto Scaling to dynamically adjust the number of instances based on traffic.\n\n2. **Load Balancing**:\n   - **Amazon Application Load Balancer (ALB)**: Use an ALB to distribute incoming traffic across your ECS or EKS instances. This will help manage the load and ensure high availability.\n\n3. **Storage**:\n   - **Amazon S3**: Use S3 for storing the output of your application. S3 is highly durable and scalable, making it suitable for handling large amounts of data generated by your application.\n\n4. **Database**:\n   - Depending on your application's needs, you may require a database to store user data or application state. Consider using Amazon RDS (for relational databases) or Amazon DynamoDB (for NoSQL databases) based on your requirements.\n\n5. **Caching**:\n   - **Amazon ElastiCache**: To improve performance and reduce latency, consider using ElastiCache (Redis or Memcached) to cache frequently accessed data.\n\n6. **Monitoring and Logging**:\n   - **Amazon CloudWatch**: Use CloudWatch for monitoring your application’s performance and logging. Set up alarms to notify you of any issues.\n\n7. **Security**:\n   - Implement AWS Identity and Access Management (IAM) roles and policies to control access to your resources.\n   - Use AWS Key Management Service (KMS) for encrypting sensitive data stored in S3 or databases.\n\n8. **Scaling**:\n   - Implement Auto Scaling for your ECS or EKS clusters to automatically adjust the number of running containers based on the load.\n\n9. **Content Delivery**:\n   - **Amazon CloudFront**: Use CloudFront as a Content Delivery Network (CDN) to cache and deliver your application content closer to users, improving load times.\n\n10. **Cost Management**:\n    - Use AWS Budgets and Cost Explorer to monitor and manage your costs effectively.\n\nHere’s a high-level architecture diagram:\n\n```\n[Users] --> [CloudFront] --> [Application Load Balancer] --> [ECS/EKS Cluster] --> [S3 Bucket]\n                                      |\n                                      --> [ElastiCache]\n                                      |\n                                      --> [RDS/DynamoDB]\n```\n\nThis architecture will help you efficiently deploy your Streamlit application on AWS while ensuring scalability, performance, and security. If you have any specific requirements or need further details on any component, feel free to ask
  """
    
    text_to_diagram(user_query)
    